# Music Streaming Analysis Using Spark Structured APIs

## Overview
This project analyzes music listener behavior using **PySpark Structured APIs**. It processes listening logs and song metadata to derive insights about user preferences, genre popularity, listener loyalty, and late-night listening habits.

## Dataset Description

| File | Columns | Description |
|------|---------|-------------|
| `listening_logs.csv` | `user_id`, `song_id`, `timestamp`, `duration_sec` | 1,000 listening events from 100 users across 50 songs (March 2025) |
| `songs_metadata.csv` | `song_id`, `title`, `artist`, `genre`, `mood` | Metadata for 50 songs across 5 genres and 4 moods |

Both datasets are synthetically generated by `datagen.py`.

## Repository Structure
```
├── datagen.py             # Generates synthetic input CSVs
├── main.py                # PySpark analysis script (4 tasks)
├── README.md              # This file
├── Requirements           # Project dependencies
├── listening_logs.csv     # Generated input (listening events)
├── songs_metadata.csv     # Generated input (song metadata)
└── outputs/               # Analysis results
    ├── task1_user_favorite_genres/
    ├── task2_avg_listen_time/
    ├── task3_genre_loyalty/
    └── task4_night_listeners/
```

## Output Directory Structure
Each task writes its output as a CSV file inside `outputs/`:

| Folder | Contents |
|--------|----------|
| `task1_user_favorite_genres/` | Each user's most-listened genre |
| `task2_avg_listen_time/` | Average listen duration per genre |
| `task3_genre_loyalty/` | Top 10 users ranked by genre loyalty score |
| `task4_night_listeners/` | Users who listened between 12 AM and 5 AM |

## Tasks and Outputs

### Task 1 — User Favorite Genres
For each user, counts listens per genre and selects the genre with the highest count using a window function (`row_number`).

### Task 2 — Average Listen Time per Genre
Groups all listening events by genre and computes the average `duration_sec`.

### Task 3 — Genre Loyalty Scores (Top 10)
Defines **loyalty score** as `(plays of top genre) / (total plays)` per user. Ranks users by loyalty score in descending order and outputs the top 10.

### Task 4 — Night-Owl Users (12 AM – 5 AM)
Extracts the hour from each event's timestamp and filters for hours between 0 (inclusive) and 5 (exclusive). Returns distinct users who listened during this window.

## Execution Instructions
### Prerequisites

Before starting the assignment, ensure you have the following software installed and properly configured on your machine:

1. **Python 3.x**:
   - [Download and Install Python](https://www.python.org/downloads/)
   - Verify installation:
     ```bash
     python3 --version
     ```

2. **PySpark**:
   - Install using pip:
     ```bash
     pip install pyspark
     ```

3. **Apache Spark**:
   - Ensure Spark is installed. You can download it from the [Apache Spark Downloads](https://spark.apache.org/downloads.html) page.
   - Verify installation by running:
     ```bash
     spark-submit --version
     ```

### Running the Analysis Tasks

#### Running Locally

1. **Generate the Input**:
  ```bash
   python datagen.py
   ```

2. **Execute Each Task Using spark-submit**:
   ```bash
     spark-submit main.py
   ```

3. **Verify the Outputs**:
   Check the outputs/ directory for the resulting files:
   ```bash
   ls outputs/
   ```

## Errors and Resolutions

| Error | Resolution |
|-------|------------|
| `ModuleNotFoundError: No module named 'pyspark'` | Run `pip install pyspark` |
| Output directory already exists | The script handles this automatically by removing existing output folders before writing |
| `java.lang.IllegalArgumentException` related to Spark/Java | Ensure Java 8+ is installed and `JAVA_HOME` is set |
